#ifndef LEX_H
#define LEX_H

#include <regex>
#include <stdio.h>
#include "string.h"
#include <stdlib.h>
#include <fstream>
#include <vector>
#include <iostream>
#include <iomanip>
#include <optional>

#include <result.h>

enum Token_kind {
    _EOF = 0,

{% set seen = namespace(kinds=[]) %}
{% for section in enum_sections %}
    {{ section.start_marker }},
{% if section.start_marker == "SPECIAL_RULE_KINDS_TOP" %}
    // Token kinds generated from matchers
    RULE,
{% for m in matchers %}
{% if m.replacement %}
{%- set current_kind = m.kind if m.kind else m.pattern.upper() -%}
    {%- if current_kind not in seen.kinds %}
    {{ current_kind }},
        {%- set seen.kinds = seen.kinds + [current_kind] -%}
    {%- endif %}
{% endfor %}
    // Explicit Extras
{% for extra in section.extras %}
    {%- if extra not in seen.kinds %}
    {{ extra }},
        {%- set seen.kinds = seen.kinds + [extra] -%}
    {%- endif %}
{% endfor %}
{% else %}
    // Explicit Items
{% for st in section.syntax_tokens %}
    {%- if st not in seen.kinds %}
    {{ st }},
        {%- set seen.kinds = seen.kinds + [st] -%}
    {%- endif %}
{% endfor %}
{% endif %}
    {{ section.end_marker }},

{% endfor %}
};

inline std::string kind_as_str(const Token_kind& kind);

struct Token{
    std::string value;
    Token_kind kind;

    bool operator==(const Token& other) const {
        return (value == other.value) && (kind == other.kind);
    }

    friend std::ostream& operator<<(std::ostream& stream, const Token t){
        if(t.kind == SYNTAX) std::cout << kind_as_str(t.kind) << " " << std::quoted(t.value);
        else std::cout << kind_as_str(t.kind) << " " << t.value;

        return stream;
    }
};

struct Token_matcher {

    Token_matcher(const std::string& p, const Token_kind& k){
        pattern = p;
        kind = k;
    }

    Token_matcher(const std::string& p, const Token_kind& k, std::optional<std::string> r){
        pattern = p;
        kind = k;
        replacement = r;
    }

    std::string pattern;
    Token_kind kind;
    std::optional<std::string> replacement = std::nullopt;
};

const std::vector<Token_matcher> TOKEN_RULES = {
{% for m in matchers %}
    {%- set k = m.kind if m.kind else m.pattern.upper() -%}
    {%- if m.replacement -%}
    Token_matcher("{{ m.pattern }}", {{ k }}, std::make_optional<std::string>("{{ m.replacement.replace('"', '\\"') }}")),

    {%- else -%}
    Token_matcher("{{ m.pattern }}", {{ k }}),
    
    {%- endif %}
{% endfor %}
};

const std::string FULL_REGEX = 
    R"([a-zA-Z_][a-zA-Z0-9_]*|[0-9]+(\.[0-9]+)?|#[^\n]*|\(\*|\*\)|\".*?\"|\'.*?\'|->|::|\+=|.)";


class Lexer{
    public:
        Lexer(){}

        Lexer(std::string filename)
            :_filename(filename)
        {
            lex();
        }

        std::string remove_outer_quotes(const std::string& token){
            if ((token.size() > 2) &&
                (((token.front() == '\"') && (token.back() == '\"')) ||
                ((token.front() == '\'') && (token.back() == '\'')))
            ){
                return token.substr(1, token.size() - 2);
            }

            return token;
        }

        void lex(){
            std::string input, matched_string;
            std::vector<Token> tokens;
            std::ifstream stream(_filename);

            std::regex full_pattern(FULL_REGEX, std::regex::icase);

            std::sregex_iterator end;

            bool in_multiline_comment = false;

            while(std::getline(stream, input)){
                
                std::sregex_iterator begin(input.begin(), input.end(), full_pattern);
                std::sregex_iterator end;

                for(std::sregex_iterator i = begin; i != end; ++i){
                    std::string text = i->str();

                    /*
                        ignore comments
                    */

                    if (text == "(*") {
                        in_multiline_comment = true;
                        continue; // Skip this token
                    }

                    if (text == "*)") {
                        in_multiline_comment = false;
                        continue; // Skip this token
                    }
                    
                    if (in_multiline_comment) {
                        continue;
                    }

                    if (text[0] == '#') {
                        continue; // Skip the whole comment string
                    }
                    
                    if (isspace(text[0])) {
                        continue;
                    }

                    // find exact qf tokens            
                    bool found_keyword = false;
                    
                    for(const Token_matcher& tm : TOKEN_RULES) {
                        if (text == tm.pattern) {
                            tokens.push_back(Token{tm.replacement.value_or(text), tm.kind});
                            found_keyword = true;
                            break;
                        }
                    }

                    if (found_keyword) continue;

                    
                    // classify generics
                    if (isalpha(text[0]) || text[0] == '_') {
                        tokens.push_back(Token{text, RULE});

                    } else if (isdigit(text[0])) {
                        tokens.push_back(Token{text, SYNTAX});

                    } else {
                        tokens.push_back(Token{remove_outer_quotes(text), SYNTAX});
                    }
                }
            }

            tokens.push_back(Token{.value = "", .kind = _EOF});
            result.set_ok(tokens);
        }

        void print_tokens() const {

            if(result.is_error()){
                ERROR(result.get_error());

            } else {
                std::vector<Token> tokens = result.get_ok();

                for(size_t i = 0; i < tokens.size(); ++i){
                    std::cout << tokens[i] << std::endl;
                }
            }
        }

        std::vector<Token> get_tokens(){
            std::vector<Token> tokens = result.get_ok();
            return tokens;
        }

    private:
        Result<std::vector<Token>> result;
        std::string _filename = "bnf.bnf";
        bool ignore = false;

};

inline bool is_wildcard(const Token_kind& kind) {
    return
        (kind ==  OPTIONAL) ||
        (kind == ZERO_OR_MORE) ||
        (kind == ONE_OR_MORE)
        ;
}

inline bool is_kind_of_rule(const Token_kind& kind){
    return
        (SPECIAL_RULE_KINDS_TOP < kind) &&
        (SPECIAL_RULE_KINDS_TOP > kind)
        ;
}

inline bool is_quiet(const Token_kind& kind){
    return
        (kind == SCOPE_RES) ||
        (kind == LBRACE) ||
        (kind == ARROW);
}

inline std::string kind_as_str(const Token_kind& kind) {
    for (auto tm : TOKEN_RULES){
        if(tm.kind == kind){
            return tm.pattern;
        }
    }

    return "";
}

#endif